unlist(rep)
reply_1 <- readLines('응답소_2015_01.txt')
reply_11 <- sapply(reply_1, extractNoun, USE.NAMES = F)
reply_11
head(unlist(reply_11), 30)
reply_111 <- unlist(reply_11)
reply_111
reply_11 <- str_replace_all(reply_111, '[^[:alpha:]]', '')
reply_11 <- gsub(' ','', reply_11)
reply_11
write(unlist(reply_11), 'reply_201501.txt')
rep01 <- read.table('reply_201501.txt')
rep01
rep <- union(rep01, rep02)
rep
rep000 <- union(rep01, rep02)
rep <- sapply(rep000, extractNoun, USE.NAMES = F)
head(unlist(rep), 30)
rep111 <- unlist(rep)
rep<- str_replace_all(reply111, '[^[:alpha:]]', '')
rep<- str_replace_all(rep111, '[^[:alpha:]]', '')
rep <- gsub(' ','', rep)
rep
write(unlist(rep), 'rep2015.txt')
totalrep <- read.table('rep2015.txt')
totalrep
rep000 <- union(rep01, rep02, rep03, rep04, rep05, rep06)
vec3 <- 1:10
union( vec1, vec2, vec3)
rep000 <- union(rep01, rep02)
rep001 <- union(rep01, rep02)
rep002 <- union(rep001, rep03)
rep003 <- union(rep002, rep04)
rep004 <- union(rep003, rep04)
rep004 <- union(rep003, rep05)
rep <- union(rep004, rep06)
rep <- sapply(rep000, extractNoun, USE.NAMES = F)
head(unlist(rep), 30)
rep111 <- unlist(rep)
rep<- str_replace_all(rep111, '[^[:alpha:]]', '')
rep <- gsub(' ','', rep)
rep
write(unlist(rep), 'rep2015.txt')
totalrep <- read.table('rep2015.txt')
totalrep
txt <- readLines('응답했니gsub.txt')
txt <- readLines('응답했니gsub.txt')
txt1 <- readLines('응답했니gsub.txt')
txt <- readLines('응답했니gsub.txt')
txt <- readLines('응답했니gsub.txt')
txt
cnt_txt <- length(txt)
cnt_txt
i <- 1
for(i in 1:cnt_txt) {
totalrep <- gsub((txt[i]),'',totalrep)
}
totalrep
totalrep
totalrep <- read.table('rep2015.txt')
totalrep
toralrep <- Filter(function(x){nchar(x) >= 2 & nchar(x) <=5}, totalrep)
totalrep
txt
i <- 1
for(i in 1:cnt_txt) {
totalrep <- gsub((txt[i]),'',totalrep)
}
totalrep
totalrep <- read.table('rep2015.txt')
totalrep
head(sort(totalrep, decreasing = T), 50)
wordcount <- table(totalrep)
totalrep
head(sort(wordcount, decreasing = T), 50)
txt <- readLines('응답했니gsub.txt')
txt <- readLines('응답했니gsub.txt')
txt
cnt_txt <- length(txt)
cnt_txt
i <- 1
for(i in 1:cnt_txt) {
totalrep <- gsub((txt[i]),'',totalrep)
}
totalrep
totalrep
totalrep <- read.table('rep2015.txt')
totalrep
wordcount <- table(totalrep)
totalrep
head(sort(wordcount, decreasing = T), 50)
totalrep <- gsub('\\d+','', totalrep)
totalrep <- gsub('한','', totalrep)
totalrep <- gsub('것','', totalrep)
totalrep <- gsub('수','', totalrep)
totalrep <- gsub('들','', totalrep)
totalrep <- gsub('님','', totalrep)
totalrep <- gsub('Q','', totalrep)
totalrep <- gsub('저','', totalrep)
totalrep <- gsub('일','', totalrep)
totalrep <- gsub('년','', totalrep)
totalrep
data1 <-readLines('응답소_2015_01.txt')
data2 <- sapply(data1, extractNoun, USE.NAMES = F)
data2
head(unlist(data2), 30)
cdata <- unlist(data2)
cdata
data2 <- str_replace_all(cdata, '[^[:alpha:]]', '')
data2 <- gsub(' ','', data2)
data2
txt
txt <- readLines('응답했니gsub.txt')
cnt_txt <- length(txt)
cnt_txt
i <- 1
for(i in 1:cnt_txt) {
data2 <- gsub((txt[i]),'',data2)
}
data2
data2 <- Filter(function(x){nchar(x) >= 2 & nchar(x) <=5}, data2)
data2
write(unlist(data2), 'data2.txt')
rep <- read.table('data2.txt')
nrow(rep)
wordcount <- table(rep)
head(sort(wordcount, decreasing = T), 100)
palete <- brewer.pal(9, 'RdBu')
wordcloud(names(wordcount), freq = wordcount, scale=c(3,1), rot.per = 0.1, min.freq = 100,
random.order = F, random.color = T, colors = palete)
data2
data1 <-readLines('응답소_2015_01.txt')
data2 <- sapply(data1, extractNoun, USE.NAMES = F)
data2
cdata <- unlist(data2)
cdata
data2 <- str_replace_all(cdata, '[^[:alpha:]]', '')
data2 <- gsub(' ','', data2)
data2
txt <- readLines('응답했니gsub.txt')
txt
cnt_txt <- length(txt)
cnt_txt
i <- 1
for(i in 1:cnt_txt) {
data2 <- gsub((txt[i]),'',data2)
}
data2
data2 <- Filter(function(x){nchar(x) >= 2}, data2)
data2
write(unlist(data2), 'data2.txt')
rep <- read.table('data2.txt')
nrow(rep)
wordcount <- table(rep)
head(sort(wordcount, decreasing = T), 20)
palete <- brewer.pal(9, 'RdBu')
palete <- brewer.pal(9, 'Set1')
wordcloud(names(wordcount), freq = wordcount, scale=c(3,1), rot.per = 0.1, min.freq = 100,
random.order = F, random.color = T, colors = palete)
wordcloud(names(wordcount), freq = wordcount, scale=c(5,1), rot.per = 0.1, min.freq = 100,
random.order = F, random.color = T, colors = palete)
wordcloud(names(wordcount), freq = wordcount, scale=c(5,1), rot.per = 0.1, min.freq = 5,
random.order = F, random.color = T, colors = palete)
legend(0.2, 0.9,'2015년도 1월 응답소의 질문 빈도', cex=0.8, fill=NA, border=NA, bg='white',
text.col='red', text.font=1, box.col='red')
setwd('D:/Heechul/R/R_Lecture/part2/stage1_Word Cloud/Exercise')
library(KoNLP)
library(wordcloud)
useSejongDic()
library(RColorBrewer)
library(stringr)
repl
setwd('D:/Heechul/R/R_Lecture/part2/stage1_Word Cloud/Exercise')
reply01 <- readLines("data/응답소_2015_01.txt")
reply02 <- readLines("data/응답소_2015_02.txt")
reply03 <- readLines("data/응답소_2015_03.txt")
reply04 <- readLines("data/응답소_2015_04.txt")
reply05 <- readLines("data/응답소_2015_05.txt")
reply06 <- readLines("data/응답소_2015_06.txt")
reply07 <- readLines("data/응답소_2015_07.txt")
reply08 <- readLines("data/응답소_2015_08.txt")
reply09 <- readLines("data/응답소_2015_09.txt")
reply10 <- readLines("data/응답소_2015_10.txt")
reply11 <- readLines("data/응답소_2015_11.txt")
reply12 <- readLines("data/응답소_2015_12.txt")
reply01
reply01 <- sapply(reply01, extractNoun, USE.NAMES=F)
reply01
reply01 <- unlist(reply01)
reply
reply01
reply01 <- str_replace_all(reply01, '[^[:alpha:]]','')
reply01
reply02 <- sapply(reply02, extractNoun, USE.NAMES=F)
reply02 <- unlist(reply02)
reply02
reply02 <- str_replace_all(reply02, '[^[:alpha:]]','')
reply02
totalreply <- c(reply01, reply02)
nrow(reply02)
totalreply
v1 <- 1:5
v2 <- 4:10
v1
v2
v3 <- (v1,v2)
v3 <- c(v1,v2)
v3
v1 <- c('사람','인간', '나')
v1
v2 <- c('사람', '너', '우리')
v2
v3 <- c(v1,v2)
v3
nrow(v3)
v4 <- unlist(v3)
v4
nrow(v4)
reply01 <- readLines("data/응답소_2015_01.txt")
reply01 <- sapply(reply01, extractNoun, USE.NAMES=F)
reply01 <- readLines("data/응답소_2015_01.txt")
reply01 <- sapply(reply01, extractNoun, USE.NAMES=F)
reply01
reply01 <- unlist(reply01)
reply01
tail(reply01)
nrow(reply01)
reply02 <- readLines("data/응답소_2015_02.txt")
reply03 <- readLines("data/응답소_2015_03.txt")
reply04 <- readLines("data/응답소_2015_04.txt")
reply05 <- readLines("data/응답소_2015_05.txt")
reply06 <- readLines("data/응답소_2015_06.txt")
reply07 <- readLines("data/응답소_2015_07.txt")
reply08 <- readLines("data/응답소_2015_08.txt")
reply09 <- readLines("data/응답소_2015_09.txt")
reply10 <- readLines("data/응답소_2015_10.txt")
reply11 <- readLines("data/응답소_2015_11.txt")
reply12 <- readLines("data/응답소_2015_12.txt")
## 명사만 골라낸 뒤, 제목 없애고 리스트로 만들기
reply01 <- sapply(reply01, extractNoun, USE.NAMES=F)
reply01 <- unlist(reply01)
reply02 <- sapply(reply02, extractNoun, USE.NAMES=F)
reply02 <- unlist(reply02)
reply03 <- sapply(reply03, extractNoun, USE.NAMES=F)
reply03 <- unlist(reply03)
reply04 <- sapply(reply04, extractNoun, USE.NAMES=F)
reply04 <- unlist(reply04)
reply05 <- sapply(reply05, extractNoun, USE.NAMES=F)
reply05 <- unlist(reply05)
reply06 <- sapply(reply06, extractNoun, USE.NAMES=F)
reply06 <- unlist(reply06)
reply07 <- sapply(reply07, extractNoun, USE.NAMES=F)
reply07 <- unlist(reply07)
reply08 <- sapply(reply08, extractNoun, USE.NAMES=F)
reply08 <- unlist(reply08)
reply09 <- sapply(reply09, extractNoun, USE.NAMES=F)
reply09 <- unlist(reply09)
reply10 <- sapply(reply10, extractNoun, USE.NAMES=F)
reply10 <- unlist(reply10)
reply11 <- sapply(reply11, extractNoun, USE.NAMES=F)
reply11 <- unlist(reply11)
reply12 <- sapply(reply12, extractNoun, USE.NAMES=F)
reply12 <- unlist(reply12)
reply01
reply02
reply03
reply05
reply05
reply06
reply07
reply08
reply09
reply10
reply11
reply12
totalreply <- c(reply01, reply02)
totalreply
totalreply <- c(reply01, reply02, reply03, reply04, reply05, reply06,
reply07, reply08, reply09, reply10, reply11, reply12)
totalreply
class(totalreply)
## 영어와 한글 빼놓고 다 지우기
totalreply <- str_replace_all(totalreply, '[^[:alpha:]]','')
totalreply
## 단어 없애기
totalreply <- str_replace_all(totalreply, '[^[:alpha:]]','') # 영어, 한글 빼고 지우기
totalreply <- str_replace_all(totalreply, '[A-z]','') # 모든 영문자 제거
totalreply <- str_replace_all(totalreply, '\\s','') # 공백 제거
totalreply <- str_replace_all(totalreply, '\\d','') # 숫자 제거
totalreply
## 필터로 두 글자 이상만 남기기
totalreply <- Filter(function(x) {nchar(x) >= 2}, totalreply)
totalreply <- Filter(function(x) {nchar(x) <= 6}, toralreply)
totalreply
head(totalreply, 30)
head(seoul_2015, 100)
head(totalreply, 100)
write(unlist(totalreply), '응답소gsub.txt')
head(totalreply, 100)
## 저장해서 다시 불러와 공백 없애고 필요없는 단어 확인하기
write(unlist(totalreply), 'totalreply.txt')
rev <- read.table('totalreply.txt')
rev
nrow(rev)
class(rev)
wordcount <- table(rev)
wordcount
head(sort(wordcount,decreasing=T), 100)
## txt 파일 불러와서 단어 지우기
replygsub <- readLines('replygsub.txt')
## txt 파일 불러와서 단어 지우기
replygsub <- readLines('data/replygsub.txt')
## txt 파일 불러와서 단어 지우기
replygsub <- readLines('data/replygsub.txt')
setwd('D:/Heechul/R/R_Lecture/part2/stage1_Word Cloud/Exercise')
## txt 파일 불러와서 단어 지우기
replygsub <- readLines('data/replygsub.txt')
## txt 파일 불러와서 단어 지우기
replygsub <- readLines('data/응답소gsub.txt')
replygsub
replygsub <- length(replygsub)
replygsub
i <- 1
for(i in 1:replygsub) {
totalreply <- gsub((replygsub[i]), '', totalreply)
}
totalreply
replygsub
reply01 <- readLines("data/응답소_2015_01.txt")
reply02 <- readLines("data/응답소_2015_02.txt")
reply03 <- readLines("data/응답소_2015_03.txt")
reply04 <- readLines("data/응답소_2015_04.txt")
reply05 <- readLines("data/응답소_2015_05.txt")
reply06 <- readLines("data/응답소_2015_06.txt")
reply07 <- readLines("data/응답소_2015_07.txt")
reply08 <- readLines("data/응답소_2015_08.txt")
reply09 <- readLines("data/응답소_2015_09.txt")
reply10 <- readLines("data/응답소_2015_10.txt")
reply11 <- readLines("data/응답소_2015_11.txt")
reply12 <- readLines("data/응답소_2015_12.txt")
## 명사만 골라낸 뒤, 제목 없애고 리스트로 만들기
reply01 <- sapply(reply01, extractNoun, USE.NAMES=F)
reply01 <- unlist(reply01)
reply02 <- sapply(reply02, extractNoun, USE.NAMES=F)
reply02 <- unlist(reply02)
reply03 <- sapply(reply03, extractNoun, USE.NAMES=F)
reply03 <- unlist(reply03)
reply04 <- sapply(reply04, extractNoun, USE.NAMES=F)
reply04 <- unlist(reply04)
reply05 <- sapply(reply05, extractNoun, USE.NAMES=F)
reply05 <- unlist(reply05)
reply06 <- sapply(reply06, extractNoun, USE.NAMES=F)
reply06 <- unlist(reply06)
reply07 <- sapply(reply07, extractNoun, USE.NAMES=F)
reply07 <- unlist(reply07)
reply08 <- sapply(reply08, extractNoun, USE.NAMES=F)
reply08 <- unlist(reply08)
reply09 <- sapply(reply09, extractNoun, USE.NAMES=F)
reply09 <- unlist(reply09)
reply10 <- sapply(reply10, extractNoun, USE.NAMES=F)
reply10 <- unlist(reply10)
reply11 <- sapply(reply11, extractNoun, USE.NAMES=F)
reply11 <- unlist(reply11)
reply12 <- sapply(reply12, extractNoun, USE.NAMES=F)
reply12 <- unlist(reply12)
## 리스트된 캐릭터를 하나로 합치기
totalreply <- c(reply01, reply02, reply03, reply04, reply05, reply06,
reply07, reply08, reply09, reply10, reply11, reply12)
totalreply <- str_replace_all(totalreply, '[^[:alpha:]]','') # 영어, 한글 빼고 지우기
totalreply <- str_replace_all(totalreply, '[A-z]','') # 모든 영문자 제거
totalreply <- str_replace_all(totalreply, '\\s','') # 공백 제거
totalreply <- str_replace_all(totalreply, '\\d','') # 숫자 제거
totalreply <- Filter(function(x) {nchar(x) >= 2}, totalreply)
totalreply <- Filter(function(x) {nchar(x) <= 6}, toralreply)
totalreply
## 필터로 두 글자 이상만 남기기
totalreply <- Filter(function(x) {nchar(x) >= 2}, totalreply)
totalreply <- Filter(function(x) {nchar(x) <= 6}, toralreply)
totalreply <- Filter(function(x) {nchar(x) <= 6}, totalreply)
totalreply
## 저장해서 다시 불러와 공백 없애고 필요없는 단어 확인하기
write(unlist(totalreply), 'totalreply.txt')
rev <- read.table('totalreply.txt')
rev
nrow(rev)
class(rev)
wordcount <- table(rev)
wordcount
class(wordcount)
head(sort(wordcount,decreasing=T), 100)
## txt 파일 불러와서 단어 지우기
replygsub <- readLines('data/응답소gsub.txt')
replygsub
cnt_replygsub <- length(replygsub)
cnt_replygsub
for(i in 1:cnt_replygsub) {
totalreply <- gsub((replygsub[i]), '', totalreply)
}
totalreply
## 저장해서 다시 불러와 공백 없애고 필요없는 단어 확인하기
write(unlist(totalreply), 'totalreply.txt')
rev <- read.table('totalreply.txt')
rev
nrow(rev)
wordcount <- table(rev)
wordcount
head(sort(wordcount,decreasing=T), 100)
## txt 파일 불러와서 단어 지우기
replygsub <- readLines('data/응답소gsub.txt')
replygsub
cnt_replygsub <- length(replygsub)
cnt_replygsub
for(i in 1:cnt_replygsub) {
totalreply <- gsub((replygsub[i]), '', totalreply)
}
totalreply
## 저장해서 다시 불러와 공백 없애고 필요없는 단어 확인하기(단어지우고 여기서 반복실행.두번째)
write(unlist(totalreply), 'totalreply.txt')
rev <- read.table('totalreply.txt')
rev
nrow(rev)
wordcount <- table(rev)
wordcount
head(sort(wordcount,decreasing=T), 100)
nrow(rev)
## txt 파일 불러와서 단어 지우기(여기로 와서 반복실행.첫번째)
replygsub <- readLines('data/응답소gsub.txt')
replygsub
cnt_replygsub <- length(replygsub)
cnt_replygsub
i <- 1
for(i in 1:cnt_replygsub) {
totalreply <- gsub((replygsub[i]), '', totalreply)
}
totalreply
## 저장해서 다시 불러와 공백 없애고 필요없는 단어 확인하기(단어지우고 여기서 반복실행.두번째)
write(unlist(totalreply), 'totalreply.txt')
rev <- read.table('totalreply.txt')
rev
nrow(rev)
wordcount <- table(rev)
wordcount
head(sort(wordcount,decreasing=T), 100)
### wordcloud 만들기
palete <- brewer.pal(12,"Set1")
### wordcloud 만들기
palete <- brewer.pal(9,"Set1")
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=2,
random.order=F,random.color=T,colors=palete)
par(oma=rep(0,4))
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=2,
random.order=F,random.color=T,colors=palete)
legend(0.2,0.8,"2015년 서울시 응답소 분석",cex=0.8,fill=NA,border=NA,bg="yellow",
text.col="blue",text.font=2,box.col="red")
wordcloud(names(wordcount),freq=wordcount,scale=c(4,0.4),rot.per=0.25,min.freq=2,
random.order=F,random.color=T,colors=palete)
wordcloud(names(wordcount),freq=wordcount,scale=c(4,0.4),rot.per=0.25,min.freq=5,
random.order=F,random.color=T,colors=palete)
legend(0.2,0.8,"2015년 서울시 응답소 분석",cex=0.8,fill=NA,border=NA,bg="yellow",
text.col="blue",text.font=2,box.col="red")
legend(0.2,0.8,"2015년 서울시 응답소 분석",cex=0.8,fill=NA,border=NA,bg="white",
text.col="black",text.font=2,box.col="green")
legend(0.2,1.1,"2015년 서울시 응답소 분석",cex=0.8,fill=NA,border=NA,bg="white",
text.col="black",text.font=2,box.col="green")
legend(0.2,1,"2015년 서울시 응답소 분석",cex=0.8,fill=NA,border=NA,bg="white",
text.col="black",text.font=2,box.col="green")
legend(0.2,1,"2015년 서울시 응답소 분석",cex=0.8,fill=NA,border=NA,bg="white",
text.col="black",text.font=7,box.col="green")
legend(0.2,1,'2015년 서울시 응답소 분석',cex=0.8,fill=NA,border=NA,bg="white",
text.col="black",text.font=9,box.col="green")
wordcloud(names(wordcount),freq=wordcount,scale=c(4,0.4),rot.per=0.25,min.freq=5,
random.order=F,random.color=T,colors=palete)
legend(0.2,1,'2015년 서울시 응답소 분석',cex=0.8,fill=NA,border=NA,bg="white",
text.col="black",text.font=9,box.col="green")
wordcloud(names(wordcount),freq=wordcount,scale=c(3,0.2),rot.per=0.25,min.freq=5,
random.order=F,random.color=T,colors=palete)
wordcloud(names(wordcount),freq=wordcount,scale=c(3,1),rot.per=0.25,min.freq=5,
random.order=F,random.color=T,colors=palete)
wordcloud(names(wordcount),freq=wordcount,scale=c(4,0.5),rot.per=0.25,min.freq=5,
random.order=F,random.color=T,colors=palete)
wordcloud(names(wordcount),freq=wordcount,scale=c(4,0.1),rot.per=0.25,min.freq=5,
random.order=F,random.color=T,colors=palete)
legend(0.2,1,'2015년 서울시 응답소 분석',cex=0.8,fill=NA,border=NA,bg="white",
text.col="black",text.font=9,box.col="green")
legend(0.3,1,'2015년 서울시 응답소 분석',cex=0.8,fill=NA,border=NA,bg="white",
text.col="black",text.font=9,box.col="green")
legend(0.25,1,'2015년 서울시 응답소 분석',cex=0.8,fill=NA,border=NA,bg="white",
text.col="black",text.font=9,box.col="green")
wordcloud(names(wordcount),freq=wordcount,scale=c(4,0.1),rot.per=0.25,min.freq=5,
random.order=F,random.color=T,colors=palete)
legend(0.25,1,'2015년 서울시 응답소 분석',cex=0.8,fill=NA,border=NA,bg="white",
text.col="black",text.font=9,box.col="green")
wordcloud(names(wordcount),freq=wordcount,scale=c(10,1),rot.per=0.25,min.freq=5,
random.order=F,random.color=T,colors=palete)
library(KoNLP)
library(wordcloud)
library(stringr)
library(ggplot2)
library(dplyr)
library(RColorBrewer)
useSejongDic()
### 예제 2-1. '제주도 여행코스 추천' 검색어 결과를 그래프로 표시하기
setwd('D:/Heechul/R/R_Lecture/part2/stage2/ex2-1')
# 파일 불러오기
txt <- readLines('data/jeju.txt')
txt
# 명사만 골라 내기
place <- sapply(txt, extractNoun, USE.NAMES = F)
place
# 제목 빼고 리스트로 만들기
cdata <- unlist(place)
cdata
